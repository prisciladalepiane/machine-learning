# üå≤ Compreendendo o Algoritmo Random Forest

O **Random Forest** √© um algoritmo de *Machine Learning* do tipo **ensemble** (conjunto), que constr√≥i m√∫ltiplas **√°rvores de decis√£o** e combina seus resultados para realizar previs√µes mais robustas.

Ele pertence √† classe de algoritmos de ensemble conhecida como **bagging** (*Bootstrap Aggregating*), cuja principal ideia √© reduzir a vari√¢ncia e evitar overfitting combinando v√°rios modelos fracos.

---

## üîç Como o Random Forest Funciona

### 1.  Amostragem Bootstrap

- Para cada √°rvore da floresta, o algoritmo gera um novo conjunto de dados atrav√©s de **amostragem com reposi√ß√£o** (*bootstrap*) a partir do conjunto original.
- Isso significa que alguns dados podem aparecer mais de uma vez, e outros podem n√£o aparecer.

---

### 2.  Constru√ß√£o das √Årvores de Decis√£o

- Cada conjunto de dados bootstrap √© usado para construir uma **√°rvore de decis√£o**.
- Em cada ponto de divis√£o (n√≥), √© considerado **um subconjunto aleat√≥rio de features**, o que aumenta a diversidade entre as √°rvores.
- Isso ajuda a evitar overfitting, pois cada √°rvore tem uma perspectiva diferente dos dados.

---

### 3. Sele√ß√£o de Divis√µes

- Ao contr√°rio de uma √°rvore tradicional (√∫nica) onde todas as caracter√≠sticas s√£o consideradas para fazer uma divis√£o, o Random Forest **seleciona aleatoriamente um n√∫mero limitado de vari√°veis** para encontrar a melhor divis√£o em cada n√≥.
- Essa aleatoriedade promove a diversidade e ajuda a evitar o overfitting.

---

### 4. Crescimento das √Årvores

- As √°rvores s√£o **crescidas at√© o m√°ximo**, sem poda.
- Elas continuam a se expandir at√© que cada folha seja **pura** (contendo uma √∫nica classe) ou atinja um n√∫mero m√≠nimo de amostras.

---

### 5. Previs√£o/Predi√ß√£o

- **Classifica√ß√£o**: cada √°rvore vota em uma classe, e a **classe mais votada (moda)** √© a predi√ß√£o final.
- **Regress√£o**: a **m√©dia** das previs√µes de todas as √°rvores √© usada como resultado.

---

### 6. Redu√ß√£o de Vari√¢ncia

- O Random Forest reduz a vari√¢ncia combinando os resultados de v√°rias √°rvores.
- Isso torna o modelo **mais est√°vel e menos sens√≠vel ao ru√≠do** nos dados de treinamento, se comparado a uma √∫nica √°rvore de decis√£o.

---

### 7. Import√¢ncia das Caracter√≠sticas/Features

- O algoritmo permite estimar a **import√¢ncia de cada vari√°vel** para a predi√ß√£o.
- Isso √© feito analisando a contribui√ß√£o de cada feature na **redu√ß√£o da impureza** das divis√µes ao longo da floresta.

---

## Vantagens do Random Forest

- Funciona bem para **classifica√ß√£o e regress√£o**
- **Robusto ao overfitting**, mesmo com muitas √°rvores
- Pouca necessidade de ajuste fino de hiperpar√¢metros
- Funciona com dados **n√£o normalizados** e **features irrelevantes**
- Permite **avalia√ß√£o de import√¢ncia das vari√°veis**

---

> O Random Forest √© um dos algoritmos mais usados em Machine Learning devido √† sua **efic√°cia, simplicidade** e **capacidade de generaliza√ß√£o**.
