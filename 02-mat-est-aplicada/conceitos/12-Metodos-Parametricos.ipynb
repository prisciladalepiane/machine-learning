{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d197dc",
   "metadata": {},
   "source": [
    "# Métodos Paramétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065b228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro, ttest_ind, levene, bartlett, f_oneway\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de75b68",
   "metadata": {},
   "source": [
    "## O Que São Testes Paramétricos?\n",
    "\n",
    "Os testes estatísticos paramétricos são métodos de inferência estatística que fazem suposições sobre a forma ou os parâmetros da distribuição populacional da qual as amostras são retiradas. Esses testes são usados para determinar se existem diferenças significativas entre grupos, se existe correlação entre variáveis, entre outras análises, com base nas propriedades dos parâmetros estimados, como a média e o desvio padrão.\n",
    "\n",
    "Alguns pontos-chave dos testes estatísticos paramétricos incluem:\n",
    "\n",
    "**Suposições sobre a Distribuição**: Eles geralmente assumem que os dados seguem uma distribuição específica, frequentemente a distribuição normal. Isso é importante porque a validade dos resultados dos testes depende do quão bem essas suposições se alinham com os dados reais.\n",
    "\n",
    "**Informações sobre Parâmetros**: Eles lidam com parâmetros específicos da população, como a média (μ) ou a variância (σ2), e frequentemente envolvem a comparação de estimativas desses parâmetros entre diferentes grupos ou condições.\n",
    "\n",
    "**Exemplos Comuns**: Incluem o teste t (para comparar as médias de dois grupos), ANOVA (Análise de Variância, para comparar as médias entre três ou mais grupos), e o teste de correlação de Pearson (para avaliar a força e a direção da relação linear entre duas variáveis contínuas).\n",
    "\n",
    "**Vantagens**: Quando suas suposições são atendidas, os testes paramétricos tendem a ser mais poderosos que os não paramétricos, o que significa que eles têm uma maior probabilidade de detectar uma verdadeira diferença ou relação quando ela existe.\n",
    "\n",
    "**Verificação das Suposições**: Antes de aplicar um teste estatístico paramétrico, é fundamental verificar se as suposições, como a normalidade da distribuição e a homogeneidade das variâncias, são atendidas. Isso pode envolver o uso de testes específicos (como o teste de Shapiro-Wilk para normalidade) ou análises gráficas (como histogramas ou gráficos Q-Q).\n",
    "\n",
    "> Os testes estatísticos paramétricos são ferramentas poderosas na análise de dados, mas a escolha entre usar um teste paramétrico ou não paramétrico deve ser guiada pela natureza dos dados e pelas suposições de cada teste.\n",
    "\n",
    "### Amostra, População, Estimação Pontual e Intervalar\n",
    "\n",
    "Em Estatística, os conceitos de amostra e população, bem como estatística e parâmetro, são fundamentais para coletar, analisar e interpretar dados.\n",
    "\n",
    "**População**: Refere-se ao conjunto completo de itens ou indivíduos que você está interessado em estudar. Por exemplo, todos os estudantes de uma universidade.\n",
    "\n",
    "**Amostra**: É um subconjunto selecionado da população. Por exemplo, um grupo de 100 estudantes escolhidos aleatoriamente da mesma universidade.\n",
    "\n",
    "**Estatística**: São medidas calculadas a partir dos dados da amostra. Por exemplo, a média das notas de um teste desse grupo de 100 estudantes.\n",
    "\n",
    "**Parâmetro**: É uma medida que descreve uma característica da população. Por exemplo, a média das notas de todos os estudantes da universidade.\n",
    "\n",
    "Simplificando, a população é o todo, a amostra é uma parte deste todo; estatística refere-se a informações obtidas da amostra, enquanto parâmetro se refere a informações que descrevem a população completa.\n",
    "\n",
    "A estimação é um processo usado para inferir o valor de um parâmetro desconhecido de uma população com base em dados amostrais. Existem dois tipos principais de estimação: estimação pontual e estimação intervalar.\n",
    "\n",
    "A estimação pontual envolve o uso de dados de uma amostra para calcular um único valor (ou ponto) que serve como a melhor estimativa do parâmetro desconhecido da população. Este valor, conhecido como estimador pontual, representa a nossa melhor suposição para o parâmetro e é calculado a partir dos dados da amostra. Por exemplo, a média amostral (x) é um estimador pontual da média populacional (μ), e a proporção amostral (p) é um estimador pontual da proporção populacional (P).\n",
    "\n",
    "A estimação intervalar, por outro lado, reconhece a incerteza inerente à estimação a partir de amostras e, em vez de fornecer um único valor, oferece um intervalo de valores dentro do qual o parâmetro desconhecido é estimado estar com um certo nível de confiança. Este intervalo é conhecido como intervalo de confiança (IC) e é construído em torno do estimador pontual. O intervalo de confiança é definido por um limite inferior e um limite superior, com um nível de confiança associado (geralmente expresso como uma porcentagem, como 95% ou 99%) que reflete a probabilidade de que o intervalo contenha o verdadeiro valor do parâmetro.\n",
    "\n",
    "O intervalo de confiança leva em conta a variabilidade amostral e oferece uma gama de valores plausíveis para o parâmetro. Por exemplo, um intervalo de confiança de 95% para a média populacional (μ) sugere que, se repetíssemos o experimento muitas vezes, calculando um novo intervalo de confiança a partir de cada amostra, esperaríamos que aproximadamente 95% desses intervalos contivessem o verdadeiro valor de μ.\n",
    "\n",
    "### Propriedades dos Testes Paramétricos\n",
    "\n",
    "Os testes paramétricos, incluindo o Teste t de Student, o Teste F (ANOVA de Um Fator) e a ANOVA de dois fatores, partem do pressuposto de que os dados seguem uma distribuição específica, geralmente a distribuição normal. Isso significa que os testes assumem que os dados têm uma distribuição de probabilidade conhecida e definida. Essa é uma suposição fundamental que permite o uso de parâmetros da distribuição, como média e desvio padrão, na análise.\n",
    "\n",
    "Estes testes fazem inferências sobre parâmetros da população, como a média (μ) ou a variância, a partir de estatísticas amostrais. Eles são projetados para testar hipóteses relacionadas a esses parâmetros, como a igualdade de médias ou variações entre grupos.\n",
    "\n",
    "Os valores das estatísticas de teste (como o valor t no Teste t de Student e o valor F na ANOVA) são calculados usando parâmetros estimados dos dados, como a média e a variância. Estes valores são então comparados com uma distribuição teórica (distribuição t para o Teste t e distribuição F para a ANOVA) para determinar a significância estatística das observações.\n",
    "\n",
    "Quando as suposições dos testes paramétricos são atendidas, eles são geralmente mais eficientes (no sentido estatístico de ter maior poder para detectar um efeito real) do que seus equivalentes não paramétricos. Isso se deve ao fato de que utilizam mais informações sobre a distribuição dos dados.\n",
    "\n",
    "Além da normalidade, a ANOVA, por exemplo, assume que as variâncias dos grupos são iguais (homocedasticidade). Esta é outra suposição paramétrica que facilita a comparação entre grupos.\n",
    "\n",
    "Devido a essas características, os testes são classificados como paramétricos, e é essencial que os dados analisados atendam às suposições dos testes para garantir a validade dos resultados. Quando as suposições paramétricas não são satisfeitas, os testes não paramétricos, que não fazem suposições específicas sobre a distribuição dos dados, podem ser uma alternativa apropriada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb901c",
   "metadata": {},
   "source": [
    "## Teste t de Student \n",
    "\n",
    "O Teste t de Student é um teste estatístico usado para determinar **se há uma diferença significativa entre as médias de dois grupos**, que pode ser aplicado em diversas situações, incluindo quando as variações são desconhecidas e assumindo que as distribuições dos dois grupos são normais. Existem três principais variantes do teste t:\n",
    "\n",
    "- Teste t de uma amostra: Compara a média da amostra com uma média populacional conhecida.\n",
    "- Teste t de duas amostras independentes: Compara as médias de duas amostras independentes.\n",
    "- Teste t pareado: Compara as médias de duas amostras relacionadas ou emparelhadas.\n",
    "\n",
    "O teste calcula um valor t, que indica a diferença entre as médias das amostras em relação à variação observada nas amostras. Esse valor é então usado para calcular a probabilidade (valor-p) de observar tal diferença se, na realidade, não houver diferença entre as médias da população (hipótese nula).\n",
    "\n",
    "As **hipóteses** desse teste são formuladas da seguinte maneira:\n",
    "\n",
    "- **H0** Hipótese Nula: Não há diferença significativa entre as médias das duas populações. \n",
    "- **H1** Hipótese Alternativa (ou Ha): Existe uma diferença significativa entre as médias das duas populações.\n",
    "\n",
    "O teste t de duas amostras independentes pressupõe que as amostras são aleatórias, independentes entre si e que as populações de origem têm distribuições normais com variâncias iguais (homocedasticidade). Quando essas suposições não são atendidas, podem ser necessários testes alternativos ou ajustes nos procedimentos.\n",
    "\n",
    "O valor-p no teste t de duas amostras independentes é usado para determinar se a diferença observada entre as médias das duas amostras é estatisticamente significativa. A interpretação do valor-p depende do nível de significância escolhido para o teste, que é geralmente indicado por α (alfa). O nível de significância é a probabilidade de rejeitar a hipótese nula quando ela é verdadeira (erro do tipo I). Os valores de α mais comuns são 0,05 (5%) ou 0,01 (1%).\n",
    "\n",
    "Aqui está como você pode interpretar o valor-p:\n",
    "\n",
    "- Se o valor-p ≤ α: Há evidências estatísticas suficientes para rejeitar a hipótese nula. Isso significa que existe uma diferença significativa entre as médias das duas populações. A natureza dessa diferença (se uma média é maior ou menor que a outra) dependerá da direção da hipótese alternativa.\n",
    "\n",
    "- Se o valor-p > α: Não há evidências estatísticas suficientes para rejeitar a hipótese nula. Isso significa que não há diferença significativa entre as médias das duas populações, com base nos dados da amostra e no nível de significância escolhido.\n",
    "\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "Suponha que queremos testar se existe uma diferença significativa nas alturas médias de plantas tratadas com dois diferentes tipos de fertilizantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7df932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média Fertilizante A: 24.5\n",
      "Média Fertilizante B: 24.2\n"
     ]
    }
   ],
   "source": [
    "# Alturas das plantas (em cm) para cada tipo de fertilizante\n",
    "alturas_fertilizante_A = np.array([20, 21, 22, 24, 26, 28, 23, 25, 27, 29])\n",
    "alturas_fertilizante_B = np.array([19, 20, 21, 22, 24, 25, 26, 27, 28, 30])\n",
    "\n",
    "mean_A = np.mean(alturas_fertilizante_A)\n",
    "mean_B = np.mean(alturas_fertilizante_B)\n",
    "\n",
    "print(f\"Média Fertilizante A: {mean_A}\")\n",
    "print(f\"Média Fertilizante B: {mean_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e9a7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística t: 0.200\n",
      "Valor-p: 0.844\n"
     ]
    }
   ],
   "source": [
    "# Realizando o teste t de duas amostras independentes\n",
    "t_stat, p_valor = ttest_ind(alturas_fertilizante_A, alturas_fertilizante_B)\n",
    "print(f\"Estatística t: {t_stat:.3f}\")\n",
    "print(f\"Valor-p: {p_valor:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151faede",
   "metadata": {},
   "source": [
    "A estatística t no teste t de duas amostras independentes é uma medida da diferença entre as médias das duas amostras em relação à variabilidade combinada das duas amostras. \n",
    "\n",
    "**Valor de t próximo de zero**: Indica que a diferença entre as médias das duas amostras é pequena em relação à variabilidade das amostras. Isso sugere que não há uma diferença significativa entre as duas populações.\n",
    "\n",
    "**Valor de t positivo**: Indica que a média da primeira amostra é maior do que a média da segunda amostra. Quanto maior o valor de t, maior é a diferença entre as médias em relação à variabilidade.\n",
    "\n",
    "**Valor de t negativo**: Indica que a média da primeira amostra é menor do que a média da segunda amostra. Novamente, quanto maior o valor absoluto de t, maior é a diferença entre as médias em relação à variabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80def630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há evidências suficientes para rejeitar a hipótese nula. Não existe uma diferença significativa entre as médias.\n"
     ]
    }
   ],
   "source": [
    "nivel_significancia = 0.05\n",
    "\n",
    "if p_valor <= nivel_significancia:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese nula. Existe uma diferença significativa entre as médias.\")\n",
    "else:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese nula. Não existe uma diferença significativa entre as médias.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec182382",
   "metadata": {},
   "source": [
    "Não checamos uma das suposições do Teste t de Student, que as variáveis seguem uma Distribuição Normal. Podemos fazer essa checagem usando o Teste Shapiro-Wilk. Veja os detalhes no videobook a seguir.\n",
    "\n",
    "## Teste de Shapiro-Wilk\n",
    "\n",
    "O Teste de Normalidade Shapiro-Wilk é um procedimento estatístico utilizado para **avaliar se uma amostra provém de uma população normalmente distribuída**.\n",
    "\n",
    "Em termos simples, ele testa a hipótese de que os dados seguem uma distribuição normal (gaussiana). Esse teste é particularmente útil quando se quer aplicar técnicas estatísticas que assumem a normalidade dos dados, como muitos testes paramétricos.\n",
    "\n",
    "Alguns Pontos Chave Sobre o Teste Shapiro-Wilk:\n",
    "1. Teste de Hipóteses:\n",
    "\n",
    "- Hipótese nula (H0): Os dados seguem uma distribuição normal.\n",
    "- Hipótese alternativa (Ha): Os dados não seguem uma distribuição normal.\n",
    "\n",
    "2. Cálculo:\n",
    "\n",
    "O teste calcula uma estatística de teste, W, que quantifica o quão bem os dados se ajustam à distribuição normal. O valor de W varia de 0 a 1, onde valores próximos a 1 indicam que os dados estão próximos de uma distribuição normal.\n",
    "\n",
    "3. Decisão:\n",
    "\n",
    "A decisão de rejeitar ou não a hipótese nula é feita com base no valor-p obtido do teste. Um valor-p baixo (tipicamente menor que 0,05) indica evidências fortes contra a hipótese nula, sugerindo que os dados não seguem uma distribuição normal.\n",
    "\n",
    "4. Vantagens e Limitações:\n",
    "\n",
    "O teste de Shapiro-Wilk é considerado um dos testes mais poderosos para avaliação da normalidade, especialmente para amostras pequenas (n < 50).\n",
    "\n",
    "No entanto, sua eficácia pode ser reduzida com amostras muito grandes, onde pequenas desvios da normalidade podem ser detectados, levando à rejeição da hipótese nula mesmo para desvios insignificantes da normalidade.\n",
    "\n",
    "5. Uso:\n",
    "\n",
    "É frequentemente utilizado em análises preliminares de dados para determinar se técnicas paramétricas podem ser aplicadas com segurança ou se técnicas não paramétricas seriam mais adequadas devido à violação da suposição de normalidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0500d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de Shapiro-Wilk para verificar a normalidade\n",
    "stat_A, p_A = shapiro(alturas_fertilizante_A)\n",
    "stat_B, p_B = shapiro(alturas_fertilizante_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893c2e6",
   "metadata": {},
   "source": [
    "O teste Shapiro é aplicado separadamente aos dados de altura das plantas para cada tipo de fertilizante. Se o Valor-p obtido for maior que o nível de significância (tipicamente 0.05), então não temos evidências suficientes para rejeitar a hipótese nula de normalidade, sugerindo que os dados podem ser considerados normalmente distribuídos. Se o p-valor for menor que o nível de significância, há evidências suficientes para rejeitar a hipótese de normalidade, indicando que os dados podem não seguir uma distribuição normal.\n",
    "\n",
    "Lembrando que a decisão de usar o teste t de Student depende fortemente da suposição de normalidade dos dados. Se essa suposição for violada, outros testes, como testes não paramétricos, podem ser mais adequados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1129809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertilizante A - Estatística: 0.970, Valor-p: 0.892\n",
      "Fertilizante B - Estatística: 0.968, Valor-p: 0.872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fertilizante A - Estatística: {stat_A:.3f}, Valor-p: {p_A:.3f}\")\n",
    "print(f\"Fertilizante B - Estatística: {stat_B:.3f}, Valor-p: {p_B:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93b082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante A.\n",
      "Não há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante B.\n"
     ]
    }
   ],
   "source": [
    "# Interpretando os resultados\n",
    "\n",
    "nivel_significancia = 0.05\n",
    "\n",
    "if p_A > nivel_significancia:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante A.\")\n",
    "else:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante A.\")\n",
    "\n",
    "if p_B > nivel_significancia:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante B.\")\n",
    "else:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese de normalidade para o fertilizante B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827fa1f",
   "metadata": {},
   "source": [
    "## Teste F (ANOVA de Um Fator)\n",
    "\n",
    "O Teste F, também conhecido como análise de variância (ANOVA), é um procedimento estatístico usado para c**omparar as médias de três ou mais grupos para determinar se pelo menos um dos grupos difere significativamente dos outros em termos de sua média**. \n",
    "O Teste F avalia a hipótese nula de que todas as populações das quais as amostras foram retiradas têm a mesma média, contra a hipótese alternativa de que pelo menos uma média de população é diferente.\n",
    "\n",
    "O valor F é calculado dividindo a variância entre os grupos pela variância dentro dos grupos. Se a variância entre os grupos é significativamente maior do que a variância dentro dos grupos, isso sugere que pelo menos um dos grupos difere dos outros em termos de sua média, levando à rejeição da hipótese nula.\n",
    "\n",
    "Hipóteses:\n",
    "\n",
    "- Hipótese Nula (H₀): Não há diferença estatística significativa entre as médias de todos os grupos (todas as médias populacionais são iguais). \n",
    "- Hipótese Alternativa (H₁): Pelo menos uma das médias dos grupos é diferente das outras (nem todas as médias populacionais são iguais)\n",
    "\n",
    "Exemplo: Teste F (ANOVA de um fator).\n",
    "\n",
    "Suponhamos que você deseja testar se três diferentes dietas têm efeitos distintos sobre o peso de grupos de indivíduos. As três dietas são o Grupo A, Grupo B e Grupo C. Você mediu o peso perdido por um mês em cada grupo e deseja saber se há diferenças significativas entre os efeitos das dietas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90511ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso perdido por indivíduos em cada grupo de dieta (em kg)\n",
    "peso_perdido_A = np.array([2.1, 1.9, 2.2, 2.4, 2.3, 2.1, 2.2, 2.0])\n",
    "peso_perdido_B = np.array([1.5, 1.7, 1.6, 1.8, 1.5, 1.7, 1.6])\n",
    "peso_perdido_C = np.array([3.1, 3.2, 3.0, 3.3, 3.1, 3.2, 3.1, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be55de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando ANOVA de um fator\n",
    "f_stat, p_valor = f_oneway(peso_perdido_A, peso_perdido_B, peso_perdido_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e11b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística F: 266.012\n",
      "Valor-P: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estatística F: {f_stat:.3f}\")\n",
    "print(f\"Valor-P: {p_valor:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ef63d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há evidências suficientes para rejeitar a hipótese nula. Pelo menos uma das dietas tem um efeito significativamente diferente sobre o peso perdido.\n"
     ]
    }
   ],
   "source": [
    "# Interpretando o resultado\n",
    "\n",
    "nivel_significancia = 0.05\n",
    "\n",
    "if p_valor <= nivel_significancia:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese nula. Pelo menos uma das dietas tem um efeito significativamente diferente sobre o peso perdido.\")\n",
    "else:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese nula. Não há diferenças significativas entre os efeitos das dietas no peso perdido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ab457",
   "metadata": {},
   "source": [
    "Para verificar as suposições para o teste F (ANOVA), você precisa considerar principalmente duas suposições: normalidade dos resíduos e homogeneidade das variâncias entre os grupos.\n",
    "\n",
    "1. Normalidade dos Resíduos\n",
    "\n",
    "A normalidade dos resíduos pode ser verificada usando o teste de Shapiro-Wilk, similarmente ao que foi feito anteriormente. Contudo, para a ANOVA, o teste é aplicado aos resíduos do modelo, que são as diferenças entre os valores observados e os valores previstos (ajustados) pelo modelo. Normalmente, isso exigiria a construção de um modelo ANOVA usando, por exemplo, statsmodels para acessar os resíduos diretamente. Por simplicidade e como não construímos o modelo aqui, podemos verificar a normalidade dos grupos individualmente como uma aproximação inicial.\n",
    "\n",
    "2. Homogeneidade das Variâncias\n",
    "\n",
    "A homogeneidade das variâncias (também conhecida como homocedasticidade) entre os grupos pode ser verificada pelo teste de Levene ou pelo teste de Bartlett. O teste de Levene é mais robusto para distribuições que não seguem a normalidade, enquanto o teste de Bartlett é mais sensível a desvios da normalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bbbc88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor-p do teste de Shapiro-Wilk para os resíduos: 0.713\n",
      "Os resíduos seguem uma distribuição normal.\n"
     ]
    }
   ],
   "source": [
    "# Verificando a suposição de Normalidade dos Resíduos\n",
    "\n",
    "# Calculando as médias dos grupos\n",
    "media_A = np.mean(peso_perdido_A)\n",
    "media_B = np.mean(peso_perdido_B)\n",
    "media_C = np.mean(peso_perdido_C)\n",
    "\n",
    "# Calculando os resíduos\n",
    "residuos_A = peso_perdido_A - media_A\n",
    "residuos_B = peso_perdido_B - media_B\n",
    "residuos_C = peso_perdido_C - media_C\n",
    "\n",
    "# Concatenando os resíduos\n",
    "residuos = np.concatenate([residuos_A, residuos_B, residuos_C])\n",
    "\n",
    "# Testando a normalidade dos resíduos\n",
    "_, p_valor_shapiro = shapiro(residuos)\n",
    "print(f\"Valor-p do teste de Shapiro-Wilk para os resíduos: {p_valor_shapiro:.3f}\")\n",
    "\n",
    "# Interpretando o resultado do teste de Shapiro-Wilk\n",
    "if p_valor_shapiro > 0.05:\n",
    "    print(\"Os resíduos seguem uma distribuição normal.\")\n",
    "else:\n",
    "    print(\"Os resíduos não seguem uma distribuição normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb25b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor-P de Levene: 0.412\n",
      "Valor-P de Bartlett: 0.473\n",
      "Não há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Levene).\n",
      "Não há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Bartlett).\n"
     ]
    }
   ],
   "source": [
    "# Verificando a suposição de Homogeneidade das Variâncias\n",
    "\n",
    "# Teste de Levene para homogeneidade das variâncias\n",
    "_, p_levene = levene(peso_perdido_A, peso_perdido_B, peso_perdido_C)\n",
    "\n",
    "# Teste de Bartlett para homogeneidade das variâncias\n",
    "_, p_bartlett = bartlett(peso_perdido_A, peso_perdido_B, peso_perdido_C)\n",
    "\n",
    "print(f\"Valor-P de Levene: {p_levene:.3f}\")\n",
    "print(f\"Valor-P de Bartlett: {p_bartlett:.3f}\")\n",
    "\n",
    "# Interpretando os resultados\n",
    "\n",
    "nivel_significancia = 0.05\n",
    "\n",
    "if p_levene > nivel_significancia:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Levene).\")\n",
    "else:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Levene).\")\n",
    "\n",
    "if p_bartlett > nivel_significancia:\n",
    "    print(\"Não há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Bartlett).\")\n",
    "else:\n",
    "    print(\"Há evidências suficientes para rejeitar a hipótese de homogeneidade das variâncias (Bartlett).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340128bf",
   "metadata": {},
   "source": [
    "Neste exemplo, primeiro foi aplicado o teste de Shapiro-Wilk para verificar a normalidade dos resíduos. \n",
    "Depois, foi usado o teste de Levene e o teste de Bartlett para verificar a homogeneidade das variâncias entre os grupos. Os valores-p são maiores que o nível de significância (0.05), portanto, não rejeitamos as hipóteses nulas, o que significa que as suposições de normalidade e homogeneidade das variâncias foram atendidas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
